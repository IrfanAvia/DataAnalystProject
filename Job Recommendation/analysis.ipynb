{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('job_descriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop column: 'Contact'\n",
    "df = df.drop(columns=['Contact'])\n",
    "df = df.drop(columns=['Job Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Experience', 'Qualifications', 'Salary Range', 'location', 'Country',\n",
       "       'latitude', 'longitude', 'Work Type', 'Company Size',\n",
       "       'Job Posting Date', 'Preference', 'Contact Person', 'Job Title', 'Role',\n",
       "       'Job Portal', 'Job Description', 'Benefits', 'skills',\n",
       "       'Responsibilities', 'Company', 'Company Profile'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Job Id                 0\n",
       "Experience             0\n",
       "Qualifications         0\n",
       "Salary Range           0\n",
       "location               0\n",
       "Country                0\n",
       "latitude               0\n",
       "longitude              0\n",
       "Work Type              0\n",
       "Company Size           0\n",
       "Job Posting Date       0\n",
       "Preference             0\n",
       "Contact Person         0\n",
       "Contact                0\n",
       "Job Title              0\n",
       "Role                   0\n",
       "Job Portal             0\n",
       "Job Description        0\n",
       "Benefits               0\n",
       "skills                 0\n",
       "Responsibilities       0\n",
       "Company                0\n",
       "Company Profile     5478\n",
       "Posting Year           0\n",
       "Posting Month          0\n",
       "Min Salary             0\n",
       "Max Salary             0\n",
       "Avg Salary             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Job Posting Date'] = pd.to_datetime(df['Job Posting Date'])\n",
    "\n",
    "df['Posting Year'] = df['Job Posting Date'].dt.year\n",
    "df['Posting Month'] = df['Job Posting Date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Posting Year and count job postings\n",
    "job_trends = df.groupby('Posting Year').size().reset_index(name='Job Postings')\n",
    "\n",
    "# Feature matrix (X) and target variable (y)\n",
    "X = job_trends[['Posting Year']]\n",
    "y = job_trends['Job Postings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1,)\n"
     ]
    }
   ],
   "source": [
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'xgboost'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mxgboost\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m XGBRegressor\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Initialize and train the XGBoost model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m model \u001b[38;5;241m=\u001b[39m XGBRegressor(n_estimators\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'xgboost'"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "model = XGBRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate model performance\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(f\"Mean Squared Error: {mse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Menggunakan model untuk memprediksi jumlah job postings untuk tahun 2021-2023\u001b[39;00m\n\u001b[0;32m      4\u001b[0m X_test \u001b[38;5;241m=\u001b[39m job_trends[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPosting Year\u001b[39m\u001b[38;5;124m'\u001b[39m]]  \u001b[38;5;66;03m# Fitur yang digunakan (misalnya Posting Year)\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mpredict(X_test)  \u001b[38;5;66;03m# Prediksi dari model\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Tambahkan kolom 'Predicted Job Postings' ke DataFrame\u001b[39;00m\n\u001b[0;32m      8\u001b[0m job_trends[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPredicted Job Postings\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Menggunakan model untuk memprediksi jumlah job postings untuk tahun 2021-2023\n",
    "X_test = job_trends[['Posting Year']]  # Fitur yang digunakan (misalnya Posting Year)\n",
    "y_pred = model.predict(X_test)  # Prediksi dari model\n",
    "\n",
    "# Tambahkan kolom 'Predicted Job Postings' ke DataFrame\n",
    "job_trends['Predicted Job Postings'] = y_pred\n",
    "\n",
    "# Filter data untuk tahun 2021 hingga 2023\n",
    "filtered_data = job_trends[(job_trends['Posting Year'] >= 2021) & (job_trends['Posting Year'] <= 2023)]\n",
    "\n",
    "# Visualisasikan data aktual dan prediksi\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(filtered_data['Posting Year'], filtered_data['Job Postings'], label='Actual Job Postings', marker='o')\n",
    "plt.plot(filtered_data['Posting Year'], filtered_data['Predicted Job Postings'], label='Predicted Job Postings', linestyle='--', marker='x')\n",
    "\n",
    "# Tambahkan label dan judul\n",
    "plt.xlabel('Posting Year')\n",
    "plt.ylabel('Job Postings')\n",
    "plt.title('Actual vs Predicted Job Market Trends (2021-2023)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Tampilkan plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_salary_range(salary_range):\n",
    "    # Hapus tanda dolar dan huruf 'K'\n",
    "    salary_range = salary_range.replace('$', '').replace('K', '')\n",
    "    \n",
    "    # Pisahkan range gaji (misal: '59-99' menjadi [59, 99])\n",
    "    salary_min, salary_max = salary_range.split('-')\n",
    "    \n",
    "    # Konversi ke numerik dan kalikan 1000\n",
    "    salary_min = float(salary_min) * 1000\n",
    "    salary_max = float(salary_max) * 1000\n",
    "    \n",
    "    return salary_min, salary_max\n",
    "# Clean and preprocess the 'Skills', 'Qualifications', and 'Job Description' columns\n",
    "df['skills'] = df['skills'].fillna('').str.lower()\n",
    "df['Qualifications'] = df['Qualifications'].fillna('').str.lower()\n",
    "df['Job Description'] = df['Job Description'].fillna('').str.lower()\n",
    "\n",
    "# Convert 'Salary Range' into numeric values (use the previously discussed method to extract Min and Max salary)\n",
    "df[['Min Salary', 'Max Salary']] = df['Salary Range'].apply(lambda x: pd.Series(clean_salary_range(x)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Use TF-IDF to vectorize the 'Skills' column\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = tfidf.fit_transform(df['skills'])\n",
    "\n",
    "# Function to recommend jobs based on skills\n",
    "def recommend_jobs(job_seeker_skills, top_n=5):\n",
    "    # Convert job seeker's skills to a vector\n",
    "    seeker_skills_vector = tfidf.transform([job_seeker_skills.lower()])\n",
    "    \n",
    "    # Compute cosine similarity between job seeker's skills and all job postings\n",
    "    cosine_sim = cosine_similarity(seeker_skills_vector, tfidf_matrix).flatten()\n",
    "    \n",
    "    # Get the top N jobs with highest similarity\n",
    "    top_jobs_indices = cosine_sim.argsort()[-top_n:][::-1]\n",
    "    \n",
    "    # Return the recommended jobs\n",
    "    return df.iloc[top_jobs_indices][['Job Title', 'Company', 'skills', 'Salary Range']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Job Title                   Company  \\\n",
      "630408   Data Scientist      Bristol-Myers Squibb   \n",
      "137643   Data Scientist                      Olin   \n",
      "655749   Data Scientist  TravelCenters of America   \n",
      "1069428  Data Scientist     L3Harris Technologies   \n",
      "857581   Data Scientist              W.R. Berkley   \n",
      "\n",
      "                                                    skills Salary Range  \n",
      "630408   machine learning algorithms python programming...   $58K-$125K  \n",
      "137643   machine learning algorithms python programming...   $58K-$112K  \n",
      "655749   machine learning algorithms python programming...   $60K-$114K  \n",
      "1069428  machine learning algorithms python programming...    $58K-$85K  \n",
      "857581   machine learning algorithms python programming...   $64K-$120K  \n"
     ]
    }
   ],
   "source": [
    "# Example usage: recommend jobs based on a job seeker's skills\n",
    "job_seeker_skills = \"python, machine learning, data analysis\"\n",
    "recommended_jobs = recommend_jobs(job_seeker_skills)\n",
    "print(recommended_jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter jobs based on a desired salary range (e.g., $60,000 - $100,000)\n",
    "desired_min_salary = 60000\n",
    "desired_max_salary = 100000\n",
    "\n",
    "# Filter the DataFrame\n",
    "salary_matched_jobs = df[(df['Min Salary'] >= desired_min_salary) & (df['Max Salary'] <= desired_max_salary)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Job Title               Company  \\\n",
      "1182591  Data Scientist                  AGCO   \n",
      "88352    Data Scientist           Wells Fargo   \n",
      "659611   Data Scientist                Sempra   \n",
      "939425   Data Scientist  State Farm Insurance   \n",
      "134294   Data Scientist          Ryder System   \n",
      "\n",
      "                                                    skills Salary Range  \\\n",
      "1182591  machine learning algorithms python programming...    $63K-$95K   \n",
      "88352    machine learning algorithms python programming...    $60K-$84K   \n",
      "659611   machine learning algorithms python programming...    $61K-$86K   \n",
      "939425   machine learning algorithms python programming...    $62K-$98K   \n",
      "134294   machine learning algorithms python programming...    $64K-$91K   \n",
      "\n",
      "         Skill Similarity  \n",
      "1182591          0.609868  \n",
      "88352            0.609868  \n",
      "659611           0.609868  \n",
      "939425           0.609868  \n",
      "134294           0.609868  \n"
     ]
    }
   ],
   "source": [
    "# Combine all criteria: skills, location, and salary\n",
    "def recommend_jobs_combined(job_seeker_skills, desired_min_salary, desired_max_salary, top_n=5):\n",
    "    # Step 1: Skills filtering\n",
    "    seeker_skills_vector = tfidf.transform([job_seeker_skills.lower()])\n",
    "    cosine_sim = cosine_similarity(seeker_skills_vector, tfidf_matrix).flatten()\n",
    "    df['Skill Similarity'] = cosine_sim\n",
    "    \n",
    "   \n",
    "    \n",
    "    # Step 3: Salary filtering\n",
    "    filtered_jobs = df[(df['Min Salary'] >= desired_min_salary) & \n",
    "                       (df['Max Salary'] <= desired_max_salary) ]  # Within 50 km\n",
    "    \n",
    "    # Sort by skill similarity and get top N jobs\n",
    "    top_jobs = filtered_jobs.sort_values(by='Skill Similarity', ascending=False).head(top_n)\n",
    "    \n",
    "    return top_jobs[['Job Title', 'Company', 'skills', 'Salary Range',  'Skill Similarity']]\n",
    "\n",
    "# Example: Recommend jobs based on all criteria\n",
    "recommended_jobs_combined = recommend_jobs_combined(\"python, machine learning, data analysis\", 60000, 100000)\n",
    "print(recommended_jobs_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job Title</th>\n",
       "      <th>Company</th>\n",
       "      <th>skills</th>\n",
       "      <th>Salary Range</th>\n",
       "      <th>Skill Similarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1160895</th>\n",
       "      <td>Electrical Designer</td>\n",
       "      <td>Constellation Energy</td>\n",
       "      <td>electrical engineering circuit design electron...</td>\n",
       "      <td>$55K-$112K</td>\n",
       "      <td>0.467321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348030</th>\n",
       "      <td>Electrical Designer</td>\n",
       "      <td>AutoZone</td>\n",
       "      <td>electrical engineering circuit design electron...</td>\n",
       "      <td>$58K-$88K</td>\n",
       "      <td>0.467321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335545</th>\n",
       "      <td>Electrical Designer</td>\n",
       "      <td>Cisco Systems</td>\n",
       "      <td>electrical engineering circuit design electron...</td>\n",
       "      <td>$60K-$97K</td>\n",
       "      <td>0.467321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762816</th>\n",
       "      <td>Electrical Designer</td>\n",
       "      <td>Global Partners</td>\n",
       "      <td>electrical engineering circuit design electron...</td>\n",
       "      <td>$58K-$91K</td>\n",
       "      <td>0.467321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1068505</th>\n",
       "      <td>Electrical Designer</td>\n",
       "      <td>Pacific Life</td>\n",
       "      <td>electrical engineering circuit design electron...</td>\n",
       "      <td>$65K-$117K</td>\n",
       "      <td>0.467321</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Job Title               Company  \\\n",
       "1160895  Electrical Designer  Constellation Energy   \n",
       "348030   Electrical Designer              AutoZone   \n",
       "335545   Electrical Designer         Cisco Systems   \n",
       "762816   Electrical Designer       Global Partners   \n",
       "1068505  Electrical Designer          Pacific Life   \n",
       "\n",
       "                                                    skills Salary Range  \\\n",
       "1160895  electrical engineering circuit design electron...   $55K-$112K   \n",
       "348030   electrical engineering circuit design electron...    $58K-$88K   \n",
       "335545   electrical engineering circuit design electron...    $60K-$97K   \n",
       "762816   electrical engineering circuit design electron...    $58K-$91K   \n",
       "1068505  electrical engineering circuit design electron...   $65K-$117K   \n",
       "\n",
       "         Skill Similarity  \n",
       "1160895          0.467321  \n",
       "348030           0.467321  \n",
       "335545           0.467321  \n",
       "762816           0.467321  \n",
       "1068505          0.467321  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Recommend jobs based on all criteria\n",
    "recommended_jobs_combined = recommend_jobs_combined(\"electrical\", 10000, 120000)\n",
    "recommended_jobs_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSON: John Doe\n",
      "Python\n",
      "DATE: 5 years\n",
      "PERSON: Django\n",
      "ORG: TensorFlow\n",
      "PERSON: Docker\n",
      "ORG: ABC Corp\n",
      "DATE: 2018-2023\n",
      "ORG: Computer Science\n",
      "ORG: XYZ University\n",
      "Skills: ['Python, Django, TensorFlow, Docker, AWS']\n",
      "Experience: ['Python Developer at ABC Corp (2018-2023)']\n",
      "Education: ['BSc in Computer Science, XYZ University']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "import re\n",
    "\n",
    "# Load pre-trained NLP model (spaCy's en_core_web_sm)\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "# Example resume text\n",
    "resume_text = \"\"\"\n",
    "John Doe\n",
    "Python Developer with 5 years of experience in machine learning and web development.\n",
    "Skills: Python, Django, TensorFlow, Docker, AWS\n",
    "Experience: Python Developer at ABC Corp (2018-2023)\n",
    "Education: BSc in Computer Science, XYZ University\n",
    "Contact: johndoe@example.com, +1234567890\n",
    "\"\"\"\n",
    "\n",
    "# Preprocess the resume text\n",
    "def clean_resume(text):\n",
    "    # Remove email addresses, phone numbers, and other irrelevant information\n",
    "    text = re.sub(r'\\S+@\\S+', '', text)  # Remove emails\n",
    "    text = re.sub(r'\\+\\d{9,}', '', text)  # Remove phone numbers\n",
    "    return text\n",
    "\n",
    "# Parse the resume using spaCy\n",
    "doc = nlp(clean_resume(resume_text))\n",
    "\n",
    "# Extract specific entities (NER)\n",
    "for ent in doc.ents:\n",
    "    print(f\"{ent.label_}: {ent.text}\")\n",
    "\n",
    "# Example: Extracting skills, experience, and education manually\n",
    "skills = re.findall(r\"Skills: (.+)\", resume_text)\n",
    "experience = re.findall(r\"Experience: (.+)\", resume_text)\n",
    "education = re.findall(r\"Education: (.+)\", resume_text)\n",
    "\n",
    "print(\"Skills:\", skills)\n",
    "print(\"Experience:\", experience)\n",
    "print(\"Education:\", education)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Jobs based on resume:\n",
      "               Job Title                 Company  \\\n",
      "101519  Systems Engineer               JSW Steel   \n",
      "157953  Systems Engineer    Publix Super Markets   \n",
      "259665  Systems Engineer                BT Group   \n",
      "800489  Systems Engineer          Brewin Dolphin   \n",
      "560364  Systems Engineer  Casey's General Stores   \n",
      "\n",
      "                                          Job Description  \\\n",
      "101519  As a Cloud Systems Engineer, you will be respo...   \n",
      "157953  As a Cloud Systems Engineer, you will be respo...   \n",
      "259665  As a Cloud Systems Engineer, you will be respo...   \n",
      "800489  As a Cloud Systems Engineer, you will be respo...   \n",
      "560364  As a Cloud Systems Engineer, you will be respo...   \n",
      "\n",
      "                                                   skills  \n",
      "101519  Cloud systems engineering Cloud infrastructure...  \n",
      "157953  Cloud systems engineering Cloud infrastructure...  \n",
      "259665  Cloud systems engineering Cloud infrastructure...  \n",
      "800489  Cloud systems engineering Cloud infrastructure...  \n",
      "560364  Cloud systems engineering Cloud infrastructure...  \n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Job descriptions dataset (simplified example)\n",
    "job_descriptions = df['Job Description'].fillna('').tolist()\n",
    "\n",
    "# Resume skills extracted earlier\n",
    "resume_skills = skills[0]  # Assuming skills are extracted as a string\n",
    "\n",
    "# Create TF-IDF vectors for both resume and job descriptions\n",
    "vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(job_descriptions + [resume_skills])\n",
    "\n",
    "# Calculate cosine similarity between the resume and all job descriptions\n",
    "cosine_sim = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()\n",
    "\n",
    "# Get top 5 job matches based on similarity\n",
    "top_matches = cosine_sim.argsort()[-5:][::-1]\n",
    "recommended_jobs = df.iloc[top_matches][['Job Title', 'Company', 'Job Description', 'skills']]\n",
    "\n",
    "print(\"Recommended Jobs based on resume:\")\n",
    "print(recommended_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Job Title                 Company  \\\n",
      "101519  Systems Engineer               JSW Steel   \n",
      "157953  Systems Engineer    Publix Super Markets   \n",
      "259665  Systems Engineer                BT Group   \n",
      "800489  Systems Engineer          Brewin Dolphin   \n",
      "560364  Systems Engineer  Casey's General Stores   \n",
      "\n",
      "                                                   skills  \n",
      "101519  cloud systems engineering cloud infrastructure...  \n",
      "157953  cloud systems engineering cloud infrastructure...  \n",
      "259665  cloud systems engineering cloud infrastructure...  \n",
      "800489  cloud systems engineering cloud infrastructure...  \n",
      "560364  cloud systems engineering cloud infrastructure...  \n"
     ]
    }
   ],
   "source": [
    "def parse_resume(resume_text):\n",
    "    doc = nlp(clean_resume(resume_text))\n",
    "    skills = re.findall(r\"Skills: (.+)\", resume_text)\n",
    "    experience = re.findall(r\"Experience: (.+)\", resume_text)\n",
    "    education = re.findall(r\"Education: (.+)\", resume_text)\n",
    "    \n",
    "    return {\n",
    "        'skills': skills[0] if skills else '',\n",
    "        'experience': experience[0] if experience else '',\n",
    "        'education': education[0] if education else ''\n",
    "    }\n",
    "\n",
    "def recommend_jobs(resume_text, job_descriptions_df):\n",
    "    # Parse the resume\n",
    "    resume_data = parse_resume(resume_text)\n",
    "    \n",
    "    # Job descriptions from the dataset\n",
    "    job_descriptions = job_descriptions_df['Job Description'].fillna('').tolist()\n",
    "    \n",
    "    # Create TF-IDF vectors\n",
    "    vectorizer = TfidfVectorizer(stop_words='english')\n",
    "    tfidf_matrix = vectorizer.fit_transform(job_descriptions + [resume_data['skills']])\n",
    "    \n",
    "    # Calculate similarity\n",
    "    cosine_sim = cosine_similarity(tfidf_matrix[-1], tfidf_matrix[:-1]).flatten()\n",
    "    \n",
    "    # Get top job matches\n",
    "    top_matches = cosine_sim.argsort()[-5:][::-1]\n",
    "    recommended_jobs = job_descriptions_df.iloc[top_matches][['Job Title', 'Company', 'skills']]\n",
    "    \n",
    "    return recommended_jobs\n",
    "\n",
    "# Example usage\n",
    "resume_text = \"\"\"\n",
    "John Doe\n",
    "Python Developer with 5 years of experience in machine learning and web development.\n",
    "Skills: Python, Django, TensorFlow, Docker, AWS\n",
    "Experience: Python Developer at ABC Corp (2018-2023)\n",
    "Education: BSc in Computer Science, XYZ University\n",
    "Contact: johndoe@example.com, +1234567890\n",
    "\"\"\"\n",
    "\n",
    "recommended_jobs = recommend_jobs(resume_text, df)\n",
    "print(recommended_jobs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 10\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Encode the resume skills and job descriptions\u001b[39;00m\n\u001b[0;32m      9\u001b[0m resume_embedding \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mencode(resume_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskills\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m---> 10\u001b[0m job_embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjob_descriptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Compute cosine similarities\u001b[39;00m\n\u001b[0;32m     13\u001b[0m cosine_sim \u001b[38;5;241m=\u001b[39m cosine_similarity([resume_embedding], job_embeddings)\u001b[38;5;241m.\u001b[39mflatten()\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:601\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[1;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[0;32m    598\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[0;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m--> 601\u001b[0m     out_features \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward(features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    602\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice\u001b[38;5;241m.\u001b[39mtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    603\u001b[0m         out_features \u001b[38;5;241m=\u001b[39m copy\u001b[38;5;241m.\u001b[39mdeepcopy(out_features)\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py:668\u001b[0m, in \u001b[0;36mSentenceTransformer.forward\u001b[1;34m(self, input, **kwargs)\u001b[0m\n\u001b[0;32m    666\u001b[0m     module_kwarg_keys \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule_kwargs\u001b[38;5;241m.\u001b[39mget(module_name, [])\n\u001b[0;32m    667\u001b[0m     module_kwargs \u001b[38;5;241m=\u001b[39m {key: value \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m module_kwarg_keys}\n\u001b[1;32m--> 668\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m module(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodule_kwargs)\n\u001b[0;32m    669\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\sentence_transformers\\models\\Transformer.py:118\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, features, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[0;32m    116\u001b[0m     trans_features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 118\u001b[0m output_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mtrans_features, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    119\u001b[0m output_tokens \u001b[38;5;241m=\u001b[39m output_states[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    121\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_embeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m: output_tokens, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m: features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mattention_mask\u001b[39m\u001b[38;5;124m\"\u001b[39m]})\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1078\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1075\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1076\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m-> 1078\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membeddings\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1080\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1081\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1082\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1083\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1084\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1086\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m attention_mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1087\u001b[0m     attention_mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((batch_size, seq_length \u001b[38;5;241m+\u001b[39m past_key_values_length), device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\transformers\\models\\bert\\modeling_bert.py:211\u001b[0m, in \u001b[0;36mBertEmbeddings.forward\u001b[1;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[0;32m    208\u001b[0m         token_type_ids \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(input_shape, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_ids\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m    210\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 211\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mword_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    212\u001b[0m token_type_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoken_type_embeddings(token_type_ids)\n\u001b[0;32m    214\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\torch\\nn\\modules\\module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Irfan\\.conda\\envs\\ds39\\lib\\site-packages\\torch\\nn\\functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Parsing resume dan menyimpan hasilnya ke dalam resume_data\n",
    "resume_data = parse_resume(resume_text)\n",
    "# Load a pre-trained BERT-based model\n",
    "model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "\n",
    "# Encode the resume skills and job descriptions\n",
    "resume_embedding = model.encode(resume_data['skills'])\n",
    "job_embeddings = model.encode(job_descriptions)\n",
    "\n",
    "# Compute cosine similarities\n",
    "cosine_sim = cosine_similarity([resume_embedding], job_embeddings).flatten()\n",
    "\n",
    "# Get top job matches\n",
    "top_matches = cosine_sim.argsort()[-5:][::-1]\n",
    "recommended_jobs = df.iloc[top_matches][['Job Title', 'Company', 'skills']]\n",
    "\n",
    "print(recommended_jobs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ds39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
